{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Creating the NER model for use in the auto admin app (personal details removed)\n","Run on Colab"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27746,"status":"ok","timestamp":1678730792415,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"a4X1WSYgl_ZH","outputId":"ba0b30f4-fa52-4583-808c-46f6b2d150bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#mounting the drive to access datafiles\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76324,"status":"ok","timestamp":1678730868733,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"tF4h1RWHm-Sg","outputId":"e0ac12b2-f4ba-454a-87a9-95ba07f2e52a"},"outputs":[],"source":["#import & installs\n","\n","!pip install -U pip setuptools wheel\n","!pip install -U spacy\n","!pip install spacy-transformers\n","!spacy download en_core_web_trf\n","\n","import spacy\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6961,"status":"ok","timestamp":1678730875687,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"wa-PAokroJaU"},"outputs":[],"source":["#getting the basic small English spacy\n","#nlp=spacy.load('en_core_web_sm')\n","\n","#getting the spacy transformers pipeline\n","nlp=spacy.load('en_core_web_trf')\n","\n","#getting the ner pipeline component\n","ner=nlp.get_pipe(\"ner\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23382,"status":"ok","timestamp":1675966640355,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"-ynpPgj6t6hI","outputId":"ef90bd12-cb5e-4263-def8-6ec81a772fb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 33858 entries, 168 to 153196\n","Data columns (total 7 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   Date     33858 non-null  object\n"," 1   Subject  33858 non-null  object\n"," 2   Body     33858 non-null  object\n"," 3   From:    33858 non-null  object\n"," 4   To:      33858 non-null  object\n"," 5   Booking  33858 non-null  bool  \n"," 6   Cleaned  33858 non-null  object\n","dtypes: bool(1), object(6)\n","memory usage: 1.8+ MB\n","None\n"]}],"source":["#getting the emails dataset - for testing examples\n","\n","df = pd.read_csv('full_emails.csv')\n","df = df.loc[df['Booking'] == True] #getting only booking emails\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","print(df.info())\n","\n","#getting sample data for training spacy examples\n","pd.set_option('max_colwidth', 800) #so can read full email\n","tail = df.tail(2000) #just looking at mot recent format as thats what mostly recieve now\n","sample = tail.sample(50) #getting a random sample"]},{"cell_type":"markdown","metadata":{},"source":["TRAIN_DATA and TEST_DATA were then created but they have been removed for privacy preservation but an example of how it was created is below:\n","\n","TRAIN_DATA = [\n","    (\"[ new order: #0000 you’ve received the following order from XXXXX XXXXXXX: [order #0000] (01 june, 2022) product quantity price transfer from XXXXXXXX aéroport to XXXXXXX XXXXXXXX camp site by shuttle (private) on 02 june, 2022 at 15:30 people: 8 extras: 6 x 2. checked luggage, 6 x 1. hand luggage (#transfers_transfer_000000) 1 80,00€ subtotal: 80,00€ payment method: check availability total: 80,00€ deposit amount 40,00€ second payment amount 40,00€ billing address XXXXX XXXXXXX 3 fr0000, {\"entities\": [(14, 19, \"ORDER\"), (61, 74, \"PERSON\"), (143, 160, \"FROM\"), (164, 190, \"TO\"), (215, 228, \"DATE\"), (232, 236, \"TIME\"), (138, 147, \"PAX\"), (148, 299, \"EXTRAS\"), (389, 403, \"TOTAL\"), (404, 425, \"DEPOSIT\"), (471, 484, \"PERSON\"), (487, 493, \"DETAILS\")]})]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678730886447,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"PwF2QwNknhvT","outputId":"d4223139-e20f-43aa-94e7-4d7d7f6d4aed"},"outputs":[{"data":{"text/plain":["('ADDRESS',\n"," 'CARDINAL',\n"," 'DATE',\n"," 'DEPOSIT',\n"," 'DETAILS',\n"," 'EMAIL',\n"," 'EVENT',\n"," 'EXTRAS',\n"," 'FAC',\n"," 'FROM',\n"," 'GPE',\n"," 'LANGUAGE',\n"," 'LAW',\n"," 'LOC',\n"," 'MONEY',\n"," 'NORP',\n"," 'ORDER',\n"," 'ORDINAL',\n"," 'ORG',\n"," 'PAX',\n"," 'PERCENT',\n"," 'PERSON',\n"," 'PHONE',\n"," 'PRODUCT',\n"," 'QUANTITY',\n"," 'TIME',\n"," 'TO',\n"," 'TOTAL',\n"," 'WORK_OF_ART')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#adding the new ner labels\n","new_labels = [\"ORDER\", \"FROM\", \"TO\", \"TOTAL\", \"DEPOSIT\", \"PAX\", \"EXTRAS\", \"DETAILS\", \"ADDRESS\", \"EMAIL\", \"PHONE\"]\t\n","for i in new_labels:\n","  ner.add_label(i)\n","\n","#checking labels are added:\n","nlp.get_pipe(\"ner\").labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":553,"status":"ok","timestamp":1678730926086,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"yVGua2sBosYq","outputId":"a7d4e787-3a14-4e02-8926-d8f9f6a270d6"},"outputs":[],"source":["#coverting datasets to Spacy 3.0 format\n","import pandas as pd\n","from tqdm import tqdm\n","import spacy\n","from spacy.tokens import DocBin\n","from spacy.util import filter_spans\n","\n","nlp = spacy.blank(\"en\") # load a new blank spacy model\n","db = DocBin() # create a DocBin object\n","\n","#making training set\n","for text, annot in tqdm(TRAIN_DATA): # data in current format\n","    doc = nlp.make_doc(text) # create doc object from text\n","    ents = []\n","    for start, end, label in annot[\"entities\"]: # add character indexes\n","        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n","        if span is None:\n","            print(\"Skipping entity\")\n","        else:\n","            ents.append(span)\n","    doc.ents = filter_spans(ents) # to deal with overlapping spans\n","    #doc.ents = ents # label the text with the ents\n","    db.add(doc)\n","\n","db.to_disk(\"NER model/train.spacy\") # save the docbin object"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1678730938624,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"ibA9A42NsbMP","outputId":"a02a18d4-23a2-4a4d-b982-189c0e707fa3"},"outputs":[],"source":["nlp = spacy.blank(\"en\") # load a new blank spacy model\n","db = DocBin() # create a DocBin object\n","\n","#making test set\n","for text, annot in tqdm(TEST_DATA): # data in current format\n","    doc = nlp.make_doc(text) # create doc object from text\n","    ents = []\n","    for start, end, label in annot[\"entities\"]: # add character indexes\n","        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n","        if span is None:\n","            print(\"Skipping entity\")\n","        else:\n","            ents.append(span)\n","    #doc.ents = ents # label the text with the ents\n","    doc.ents = filter_spans(ents) # to deal with overlapping spans\n","    db.add(doc)\n","\n","db.to_disk(\"NER model/test.spacy\") # save the docbin object"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1678730994875,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"uSfKf-P5cxfA","outputId":"19c9dc71-3891-4ae7-fee2-e6f0d1e9d326"},"outputs":[{"name":"stdout","output_type":"stream","text":["ANSI_X3.4-1968\n","UTF-8\n"]}],"source":["#code to fix ssue where locale was ansi_x3.4 not utf8\n","import locale\n","print(locale.getpreferredencoding())\n","\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","print(locale.getpreferredencoding())"]},{"cell_type":"markdown","metadata":{"id":"RjsyuKqLo5l2"},"source":["The config file was cretaed on https://spacy.io/usage/training#config with following settings:\n","English; ner, GPU, accuracy\n","The resulting base-config.cfg file was download and is completed below\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12052,"status":"ok","timestamp":1678731014686,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"d3Kb1hHrpSEa","outputId":"db4f7c50-053f-4481-dd46-0357c456fefb"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-03-13 18:10:05.830782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-13 18:10:05.832402: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-13 18:10:05.832563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/drive/MyDrive/E1 - Final project/NER model UPDATED 2/config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}],"source":["!python -m spacy init fill-config \"NER model/base_config.cfg\" \"NER model/config.cfg\""]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":494,"status":"ok","timestamp":1678731059581,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"k6NlhWYXPoKK","outputId":"2cf5fd22-35d7-43bd-b715-49e4578544e8"},"outputs":[{"data":{"application/javascript":"function ClickConnect(){\nconsole.log(\"Working\");\ndocument.querySelector(\"colab-toolbar-button#connect\").click()\n}setInterval(ClickConnect,60000)\n","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["#run the following function before training to stop colab disconnecting\n","%%javascript\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}setInterval(ClickConnect,60000)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2094327,"status":"ok","timestamp":1678733158819,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"kyCet1FYpXrl","outputId":"b9bdb256-b7db-4620-fec2-131f6a3dded3"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-03-13 18:11:05.328544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-13 18:11:05.328686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-13 18:11:05.328713: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","\u001b[38;5;2m✔ Created output directory: /content/drive/MyDrive/E1 - Final\n","project/NER model UPDATED 2/output\u001b[0m\n","\u001b[38;5;4mℹ Saving to output directory: /content/drive/MyDrive/E1 - Final\n","project/NER model UPDATED 2/output\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2023-03-13 18:11:17,999] [INFO] Set up nlp object from config\n","[2023-03-13 18:11:18,032] [INFO] Pipeline: ['transformer', 'ner']\n","[2023-03-13 18:11:18,045] [INFO] Created vocabulary\n","[2023-03-13 18:11:18,050] [INFO] Finished initializing nlp object\n","Downloading (…)lve/main/config.json: 100% 481/481 [00:00<00:00, 73.3kB/s]\n","Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:01<00:00, 810kB/s]\n","Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 515kB/s]\n","Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:01<00:00, 1.22MB/s]\n","Downloading pytorch_model.bin: 100% 501M/501M [00:01<00:00, 281MB/s]\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2023-03-13 18:11:58,512] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0         303.56    563.54    0.00    0.00    0.00    0.00\n"," 40     200      172744.67  81555.91   91.07   94.44   87.93    0.91\n"," 80     400        6985.09   4511.98   89.54   86.99   92.24    0.90\n","120     600         332.83    342.68   89.36   88.24   90.52    0.89\n","160     800         132.15    137.54   87.29   85.83   88.79    0.87\n","200    1000          50.32     40.92   85.23   83.47   87.07    0.85\n","240    1200          45.40     56.81   90.21   89.08   91.38    0.90\n","280    1400           4.85      9.14   88.03   87.29   88.79    0.88\n","320    1600           4.87      4.14   88.98   87.50   90.52    0.89\n","360    1800          16.33      8.78   88.98   87.50   90.52    0.89\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/E1 - Final project/NER model UPDATED 2/output/model-last\n"]}],"source":["#training and evaluating on the train and test sets created\n","!python -m spacy train \"NER model/config.cfg\" --output \"NER model/output\" --paths.train \"NER model/train.spacy\" --paths.dev \"NER model/test.spacy\" --gpu-id 0"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4396,"status":"ok","timestamp":1678734178481,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"G2lDzQ-bx6zq"},"outputs":[],"source":["#load the best model\n","nlp = spacy.load(r\"NER model/output/model-best\") \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3500,"status":"ok","timestamp":1673947408294,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"c3YfHmSMyJ-p","outputId":"2d36f261-fd1f-48a5-bec4-8a18953db7c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["['transformer', 'ner', 'entity_ruler']\n","[('transformer', <spacy_transformers.pipeline_component.Transformer object at 0x7fcb421ba640>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7fcb4231ac80>), ('entity_ruler', <spacy.pipeline.entityruler.EntityRuler object at 0x7fcb421aca40>)]\n"]}],"source":["#results aren't good for DEPOSIT example for trying to add an entity rule for it:\n","nlp = spacy.load(r\"NER model/output/model-best\") \n","\n","#Create the Ruler and Add it to pipe\n","cfg = {\"overwrite_ents\": True}\n","ruler = nlp.add_pipe(\"entity_ruler\", after='ner', config=cfg)\n","\n","#List of Entities and Patterns (source: https://spacy.io/usage/rule-based-matching)\n","patterns = [\n","                #{\"label\": \"DEPOSIT\", \"pattern\": [{\"TEXT\": \"deposit amount\"}, {}]}\n","                {\"label\": \"DEPOSIT\", \"pattern\": [{\"LOWER\":\"deposit amount\"}, {}]}\n","          ]\n","\n","#add patterns to ruler\n","ruler.add_patterns(patterns)\n","\n","#checking have pipelines etc as needed\n","print(nlp.pipe_names)\n","print(nlp.pipeline)"]},{"cell_type":"markdown","metadata":{},"source":["To see the nlp applied to a test email run the below code "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":1142,"status":"ok","timestamp":1678734227341,"user":{"displayName":"Catrin Satchell O'Keeffe","userId":"08026743565018540046"},"user_tz":-60},"id":"FIEfhnxVstSn","outputId":"a5fbd285-657d-4e3a-c23f-9bb1d48fc372"},"outputs":[],"source":["#testing the model\n","doc = nlp(put sample sentence here)\n","\n","\n","#formatting return for jupyter\n","spacy.displacy.render(doc, style=\"ent\", jupyter=True)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOcZdAR6YUR6sx7sPV6nWC8","provenance":[{"file_id":"1S-K7JbOObQuCVG5ICqiHCz-d9pHazZMD","timestamp":1675882682309}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
